<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title></title>
	<link rel="icon" href="/assets/images/favicon.png">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="/assets/js/jquery.min.js"></script>
    <script src="/assets/js/bootstrap.min.js"></script>
    <link href="/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="/assets/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!--[if IE 7]>
    <link rel="stylesheet" href="assets/css/font-awesome-ie7.min.css">
    <![endif]-->
    <!--[if lt IE 9]>
       <script src="https://cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"></script>
       <script src="https://cdn.bootcss.com/respond.js/1.4.2/respond.js"></script>
    <![endif]-->
    <link href="/assets/css/main.css" rel="stylesheet" type="text/css">


</head>

<body>

<div class="container-fluid">
    <div class="row-fluid">
        <div class="navbar navbar-custom navbar-fixed-top" role="navigation">
            <div class="navbar-header" style="width:20%">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/"></a>
            </div>
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    
                    <li class="active"><a href="/">Home</a></li>
                    <li class="active"><a href="/archive.html">Archive</a></li>
                    <li class="active"><a href="/categories.html">Categories</a></li>
                    <!-- <li class="active"><a href="/tags.html">Tags</a></li>  -->
                    <li class="active"><a href="/photo.html">Photos</a></li>
                    <li class="active"><a href="/personal.html">Personal</a></li>
                </ul>
            </div>
        </div>
    </div>
</div>


<div class="wrap">
    <div class="container">
        <div class="row">
            <div class="col-md-3 hidden-xs">
                
<div class="sidebar well">
    <header class="sidebar-header" role="banner">
        <a href="/">
            <img src="/assets/images/avatar.jpg" class="img-circle" />
        </a>
        <!--
        <h3 class="title">
        <a href="/">Cheng's Homepage</a>
        </h3>
        -->
    </header>
    <div class="text-center">
        Cheng's Homepage

    </div>
</div>

<!--

<div class="sidebar well">
    <h1>Top Posts</h1>
    <ul>
        
            
                
                    <li><a href="/2018/01/11/photo-test2.html">photo people</a></li>
                
            
                
                    <li><a href="/2018/01/11/photo-test.html">photos dog</a></li>
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        
    </ul>
</div>

-->

<div class="sidebar well">
    <h1>Recent Posts</h1>
    <ul>
        
          <li><a href="/2018/01/11/photo-test2.html">photo people</a></li>
        
          <li><a href="/2018/01/11/photo-test.html">photos dog</a></li>
        
          <li><a href="/2017/12/25/phonon-transmission-green-function.html">Externed Green's Function Methods</a></li>
        
          <li><a href="/research/2017/09/26/old-papers-about-C60.html">Some old references on single crystal C60</a></li>
        
          <li><a href="/research/2017/09/19/nanoscale-thermal-measurement.html">Experimental techniques for nanoscale thermal measurement</a></li>
        
    </ul>
</div>

<div class="sidebar well">
   <h1> Tags </h1>
   <ul>
    
        
            <li>
              <a href="/tags.html"> Blog</a></li>
            <li>
                
    
        
            <li>
              <a href="/tags.html"> Photo</a></li>
            <li>
                
    
    </ul>
</div>

<div class="sidebar well">
    
<h1>Links</h1>
<ul>
  <!-- <li><a href="#">One</a></li>
  <li><a href="#">Two</a></li>
  <li><a href="#">Three</a></li>
  <li><a href="#">Four</a></li> -->
  
  <li>
    <a href="http://xixia.info">
      Xixia
    </a>
  </li> 
  
  <li>
    <a href="https://github.com/zxixia/jekyll-xixia">
      Jekyll-Xixia
    </a>
  </li> 
  
  <li>
    <a href="https://github.com/shaocheng16/shaocheng16.github.io/">
      Github
    </a>
  </li> 
  
</ul>

</div>

            </div>
            <div class="col-md-9">
                
<div class="well article">
        <h2><a href="/research/2017/07/22/mechine-learning-01.html">Mechine learning: 01</a></h2>
        <span class="post-date">
            
            July-22-2017
        </span>
        <hr style="border-top:1px solid #28323C;"/>
    
    <div class="post-content">
    <ul>
  <li>The problem of searching for patterns in data is fundamental one and has a long and successful history.</li>
  <li>The field of <strong>pattern recognition</strong> is concerned with the automatic discovery of <em>regularities in data</em> through the use of <strong>computer algorithms</strong> and with the use of these regularities to take action such as classifying the data into different categories.</li>
  <li>In mechine learning, a training set is used to tune the parameters of an adaptive model.</li>
  <li>In most applications, the original training sets are preprocessed to transform them into some new space of variables where, it is hoped, the pattern recognition problem will be easier to solve
    <ul>
      <li>this pre-processing stage is sometimes also called feature extraction.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="types-of-mechine-learning">Types of mechine learning:</h3>
<ul>
  <li>supervised learning
    <ul>
      <li>classification problem</li>
    </ul>
  </li>
  <li>unsupervised learning
    <ul>
      <li>to discover groups of similar examples within the data (clustering)</li>
      <li>determine the distribution of data within the input space (density estimation)</li>
      <li>project the data from high-dimensional space down to low dimensions for the purpose of <em>visualization</em>.</li>
    </ul>
  </li>
  <li>reinforcement learning
    <ul>
      <li>to find suitable actions to take in a given situation in order to maximize a reward.</li>
      <li>the learning algorithm is not given examples of optimal outputs, in contrast to supervised learning, but must instead discover them by a process of trial and error.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="example-polynomial-curve-fitting">Example: polynomial Curve Fitting</h3>
<ul>
  <li>Data generated for this example:
    <ul>
      <li>sin(2\pi x) with random noise</li>
      <li>the data sets process an underlying regularity, which we wish to learn, but that individual observations are corrupted by random noise.</li>
      <li>the noise might arise from intrinsically stochastic processes such as radioactive decay but more typically is due to there being sources of variability that are themselves unobserved.</li>
    </ul>
  </li>
  <li>Training set:
    <ul>
      <li>N observations of x: X=(x1, x2, … xN)^T</li>
      <li>the corresponding observations: T= (t1, t2, …, tN)^T</li>
    </ul>
  </li>
  <li>The goal is to exploit this training set in order to make prediction of the value t^ of the target variable for some new value x^ of the input variable.</li>
  <li>The values of the coefficients will be determined by fitting the polynomial to the training data.
    <ul>
      <li>This can be done by minimizing an error function that measures the misfit between the function y(x,W), for any given value w, and the training set data points.</li>
    </ul>
  </li>
  <li>The remain problem is the choosing the order M of the polynomial, and this will turn out to be an example of an important concept called model comparison or modelselection.
    <ul>
      <li>More flexible polynomials with larger values of M are becoming <strong>increasingly tuned to the random noise on the target values</strong>.</li>
      <li>For a given model complexity, the over-fitting problem become less severe as the the size of the data set increase.</li>
      <li><em>the number of parameters is not necessarity the most appropriate measure of model complexity.</em></li>
      <li>The over-fitting problem can be understood as a general property of maximum likelihood.</li>
      <li>The over-fitting problem can be avoided by adopting a Bayesian approach.</li>
      <li>in a Bayesian model, the <em>effective</em> number of parameters adapts automatically to the size of the data set.</li>
    </ul>
  </li>
  <li>One technique that is often used to control the over-fitting problem:
    <ul>
      <li>adding a penalty term to the error function in order to discourage the coefficients from reaching large values.</li>
    </ul>
  </li>
  <li>Take home message: if we are trying to solve a practical applications using the approach of minimizing an error function, we would have to find a way to determine a suitable value for the model complexity.</li>
</ul>

<hr />

<h3 id="probability-theory">Probability theory</h3>
<ul>
  <li>A key concept in pattern recognition is that of uncertainty:
    <ul>
      <li>noise on measurement</li>
      <li>finite size of data sets</li>
    </ul>
  </li>
</ul>

<p>Probability theory provides a consistent framework for the quantificaion and manipulation of uncertainty and forms one of the central fundations for pattern recognition.</p>
<ul>
  <li>It allows us to make optimal predictions given all the information available to us, even though that information may be incomplete or ambiguous.</li>
</ul>

<h4 id="bayesian-probabilities">Bayesian probabilities</h4>
<ul>
  <li>Classsical or frequentist interpretation of probability is based on the frequencies of random, repeatable events.</li>
  <li><strong>Bayesian view</strong>: probabilities provide a quantification of uncertainty.</li>
  <li>Bayes’ theorem was used to convert a prior probability into a posterior probability by incorporating the evidence provided by the observed data.</li>
  <li>The Bayesian framework has its origins in the 18th century, however, the practical application of Bayesian methods was for a long time severely limited by the difficulties in carrying through the full Bayesian procedure, particularly the need to marginalized over the whole of parameter space.</li>
</ul>


    <hr style="border-top:1px solid #28323C;"/>

    <!-- tags and categories under post -->
    
    <ul class="list-unstyled list-inline">
      <li><i class="icon-folder-open"></i></li>
      
      
         
            <li class="icon-style"><a href="/categories.html">
                research <span>(15)</span>
                
            </a></li>
        
      
    </ul>
      

      

    </div>
    
</div>
<div class="pagination">
    
    <a class="btn btn-default" href="/research/2017/07/24/second-thought-Green-Kubo.html" class="next">Newer Post</a>
    
    
    <a class="btn btn-default" href="/blog/2017/07/21/some-resource-for-ionic-liquid.html" class="previous">Older Post</a>
    
</div>
            </div>
        </div>
    </div>

</div>